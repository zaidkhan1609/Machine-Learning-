{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAlXYVhdn1zv",
        "outputId": "b53b8ede-3186-41cd-bf16-a09b3eef497a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add Path of the dataset below .Dataset is in the zip folder. If dataset in google drive please mount the drive Using the above line of the code **"
      ],
      "metadata": {
        "id": "IdDdTVhlAZRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/bbc-text.csv\", encoding=\"ISO-8859-1\")\n",
        "\n",
        "# Show the first 5 Rows\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YyR4Yxnn2u5",
        "outputId": "dc790936-8a7b-4b8e-b4c3-671f9b9fa73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        category                                               text\n",
            "0           tech  tv future in the hands of viewers with home th...\n",
            "1       business  worldcom boss  left books alone  former worldc...\n",
            "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
            "3          sport  yeading face newcastle in fa cup premiership s...\n",
            "4  entertainment  ocean s twelve raids box office ocean s twelve...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KLJw_qGTn63f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articles = data['text']  # Naming column 'articles' which has text\n",
        "labels = data['category']  # Naming Columns 'Labels' which has category\n",
        "\n"
      ],
      "metadata": {
        "id": "62xhTuFmoDcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# Download NLTK punkt and stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIATVjA2oSOq",
        "outputId": "ce752966-e55a-467a-8a8d-24915f3d80fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining english stopwords and the punctuation marks\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = string.punctuation\n",
        "\n",
        "def preprocess(text):\n",
        "    # Tokenize the data using word.tokenize that is in nltk.tokenize\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove punctuation and stopwords using words.isaplha which removes words that are alpha-numeric,numbers and also punctuation marks\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# creating a new column with the preprocessing of text column and calling the above function to preprocess it\n",
        "data['tokens'] = data['text'].apply(preprocess)\n",
        "\n",
        "# Show the first few tokenized texts in the tokens column\n",
        "print(data['tokens'].head())\n"
      ],
      "metadata": {
        "id": "FTyf9OCopOzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23a775a-28ef-48ee-b9d3-4485ccf27d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [tv, future, hands, viewers, home, theatre, sy...\n",
            "1    [worldcom, boss, left, books, alone, former, w...\n",
            "2    [tigers, wary, farrell, gamble, leicester, say...\n",
            "3    [yeading, face, newcastle, fa, cup, premiershi...\n",
            "4    [ocean, twelve, raids, box, office, ocean, twe...\n",
            "Name: tokens, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Word2Vec parameters\n",
        "vector_size = 100  # vectors as number of this increaes it stores more info anout the word\n",
        "window = 5         #  here it checks 5 words before and after the target word\n",
        "min_count = 2      # Ignores all words with total number of appearances  lower than this , if a word occurs less than 2 it ignores it in model\n",
        "workers = 4        # Number of worker threads to train the model\n",
        "\n",
        "# Train the Word2Vec model on tokens column on above parameters\n",
        "w2v_model = Word2Vec(sentences=data['tokens'],\n",
        "                     vector_size=vector_size,\n",
        "                     window=window,\n",
        "                     min_count=min_count,\n",
        "                     workers=workers)\n",
        "\n",
        "# Building the vocabulary and training the model on the columns and train on number of epochs which default is 5\n",
        "w2v_model.build_vocab(data['tokens'])\n",
        "w2v_model.train(data['tokens'], total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)\n"
      ],
      "metadata": {
        "id": "L6459ajAQ6YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57897b1b-e54c-4eff-abf0-6ff5c8bbf4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2243054, 2343295)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing as tfidf vector and also reducing the dimensionality using max features\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_tfidf = vectorizer.fit_transform(articles)"
      ],
      "metadata": {
        "id": "nt95KtdkF27M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Ngram for feature extraction and  also reducing the dimensionality using max features\n",
        "ngram_vectorizer = TfidfVectorizer(ngram_range=(2, 2), max_features=1000)\n",
        "X_ngrams = vectorizer.fit_transform(data['text'])\n"
      ],
      "metadata": {
        "id": "mi8TV9ZeF_GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below function is used to make vector of tokens\n",
        "def get_document_vector(tokens, model):\n",
        "    # Initialize an empty vector\n",
        "    doc_vector = np.zeros(model.vector_size)\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        if word in model.wv:\n",
        "            doc_vector += model.wv[word]\n",
        "            count += 1\n",
        "    if count != 0:\n",
        "        doc_vector /= count\n",
        "    return doc_vector\n",
        "\n",
        "# Apply the function to create document vectors\n",
        "data['doc_vector'] = data['tokens'].apply(lambda x: get_document_vector(x, w2v_model))\n",
        "\n",
        "# Convert the list of vectors into a numpy array\n",
        "X = np.vstack(data['doc_vector'].values)\n",
        "y = data['category']  # Assuming your labels are in the 'category' column\n",
        "\n",
        "# Display the shape of the feature matrix\n",
        "print(\"Feature matrix shape:\", X.shape)\n"
      ],
      "metadata": {
        "id": "4lvs9Sk8RFMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b17e149-f42c-4790-8a4b-84a47a350355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (2225, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "X_w2v_sparse = csr_matrix(X)\n",
        "# using sparse matrix to be computationally more fast\n",
        "# Combine the Word2Vec, TF-IDF, and N-gram features using hstack that is all 3 features\n",
        "X_combined = hstack([X_w2v_sparse, X_tfidf, X_ngrams])\n"
      ],
      "metadata": {
        "id": "eaiW7BbLMx3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: Train + Dev = temp vs Test which is 80-20\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Second split: Train vs Dev from the X temp 80% is now divided as 60-20\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Development set size:\", X_dev.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXR5o2_jHXbw",
        "outputId": "eb858845-23ed-4e09-881d-e3f9fbc787da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (1335, 100)\n",
            "Development set size: (445, 100)\n",
            "Test set size: (445, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the Logistic Regression model with manually set parameters acc to the dataset\n",
        "# where 'c' is used to add penalty and reduce overfitting\n",
        "# saga solver is used for multiclasss classification\n",
        "# max iter is used to Set maximum number of iterations the solver will run before stopping\n",
        "log_reg = LogisticRegression(C=10, solver='saga', max_iter=200)\n",
        "\n",
        "# Fit the Logistic Regression model on the training data\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the Development set\n",
        "y_dev_pred = log_reg.predict(X_dev)\n",
        "\n",
        "# Evaluate on the Development set\n",
        "print(\"Development Set Accuracy:\", accuracy_score(y_dev, y_dev_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_dev, y_dev_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdcHagjuHYD5",
        "outputId": "13066af3-3c67-44d8-ee6c-792fccbbffa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Development Set Accuracy: 0.9325842696629213\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     business       0.88      0.94      0.91       102\n",
            "entertainment       0.95      0.91      0.93        77\n",
            "     politics       0.99      0.90      0.94        83\n",
            "        sport       0.98      0.98      0.98       102\n",
            "         tech       0.88      0.91      0.90        81\n",
            "\n",
            "     accuracy                           0.93       445\n",
            "    macro avg       0.93      0.93      0.93       445\n",
            " weighted avg       0.93      0.93      0.93       445\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict and evaluate on the Test set as dev set accuracy is 93%\n",
        "y_test_pred = log_reg.predict(X_test)\n",
        "print(\"Test Set Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e2XgiK-dhFi",
        "outputId": "8ce056ff-db13-4143-c912-7068d00b96be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy: 0.9617977528089887\n",
            "Test Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     business       0.94      0.97      0.96       102\n",
            "entertainment       0.95      0.97      0.96        77\n",
            "     politics       0.97      0.92      0.94        84\n",
            "        sport       1.00      0.98      0.99       102\n",
            "         tech       0.94      0.96      0.95        80\n",
            "\n",
            "     accuracy                           0.96       445\n",
            "    macro avg       0.96      0.96      0.96       445\n",
            " weighted avg       0.96      0.96      0.96       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the SVM model with use parameters\n",
        "#  linear kernel to separate data with a straight hyperplane in the feature space\n",
        "# c = 1 for not overfitting\n",
        "# Predict class labels without calculating probabilities as it would be computationally more fast\n",
        "svm_clf = SVC(C=1, kernel='linear', probability=False)\n",
        "\n",
        "# Fit the SVM model on the training data as above model\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the Development set\n",
        "y_dev_pred_svm = svm_clf.predict(X_dev)\n",
        "\n",
        "# Check accuracy on the Development set\n",
        "dev_accuracy_svm = accuracy_score(y_dev, y_dev_pred_svm)\n",
        "print(\"Development Set Accuracy (SVM):\", dev_accuracy_svm)\n",
        "print(\"Classification Report (SVM - Dev Set):\\n\", classification_report(y_dev, y_dev_pred_svm))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apjKQHYHamoi",
        "outputId": "3eb405cf-24a2-4a22-822c-a1e1916f171c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Development Set Accuracy (SVM): 0.9325842696629213\n",
            "Classification Report (SVM - Dev Set):\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     business       0.88      0.95      0.92       102\n",
            "entertainment       0.93      0.92      0.93        77\n",
            "     politics       0.99      0.90      0.94        83\n",
            "        sport       0.98      0.98      0.98       102\n",
            "         tech       0.89      0.89      0.89        81\n",
            "\n",
            "     accuracy                           0.93       445\n",
            "    macro avg       0.93      0.93      0.93       445\n",
            " weighted avg       0.93      0.93      0.93       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and check accuracy on the Test set as dev set accuracy is 92.8%\n",
        "y_test_pred_svm = svm_clf.predict(X_test)\n",
        "test_accuracy_svm = accuracy_score(y_test, y_test_pred_svm)\n",
        "print(\"Test Set Accuracy (SVM):\", test_accuracy_svm)\n",
        "print(\"Classification Report (SVM - Test Set):\\n\", classification_report(y_test, y_test_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S5A32nvcxPG",
        "outputId": "814497f7-cb7b-4e91-eef0-9879acdde6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy (SVM): 0.9640449438202248\n",
            "Classification Report (SVM - Test Set):\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     business       0.95      0.96      0.96       102\n",
            "entertainment       0.97      0.99      0.98        77\n",
            "     politics       0.97      0.93      0.95        84\n",
            "        sport       0.98      0.98      0.98       102\n",
            "         tech       0.94      0.96      0.95        80\n",
            "\n",
            "     accuracy                           0.96       445\n",
            "    macro avg       0.96      0.96      0.96       445\n",
            " weighted avg       0.96      0.96      0.96       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Below we can add new txt to check the above models **"
      ],
      "metadata": {
        "id": "1y6xksCy_5bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of a new text\n",
        "new_text = \"The Share Market has been increasing day by day\"\n",
        "\n",
        "# Preprocess and create feature vector call the above functions\n",
        "tokens = preprocess(new_text)\n",
        "new_text_vector = get_document_vector(tokens, w2v_model)\n",
        "\n",
        "# Reshape to 2D array since the model expects a vector to fit in the model\n",
        "new_text_vector = new_text_vector.reshape(1, -1)\n",
        "# Make a prediction using above trained model and loading the new vector\n",
        "predicted_category = log_reg.predict(new_text_vector)\n",
        "\n",
        "# Show the reult of predeiction\n",
        "print(\"Predicted Category:\", predicted_category[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx4Z7KP_Hlja",
        "outputId": "7a2c1581-bba7-4f07-b3fd-4124f224a071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Category: business\n"
          ]
        }
      ]
    }
  ]
}